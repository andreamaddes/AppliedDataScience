{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 895117.4219185761\n",
      "R^2 Score: 0.45701817919119037\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('filtered_immoscout24.csv', delimiter=';')\n",
    "\n",
    "# Select features and the new target\n",
    "features = ['Rooms', 'Living Space (sqm)', 'Nearest Station Distance (m)', 'Canton']\n",
    "target = 'Price'  # Adjusting the target to 'Price'\n",
    "\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "# Define preprocessing for categorical data\n",
    "categorical_features = ['Canton']\n",
    "numeric_features = ['Rooms', 'Living Space (sqm)', 'Nearest Station Distance (m)']\n",
    "\n",
    "one_hot = OneHotEncoder(handle_unknown='ignore')\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', one_hot, categorical_features),\n",
    "        ('num', 'passthrough', numeric_features)\n",
    "    ])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Setup the regression pipeline\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(f'R^2 Score: {r2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the Metrics\n",
    "Root Mean Squared Error (RMSE) of 898,415: This is a very high value, suggesting that on average, the predictions of the model are off by nearly 898,415 units from the actual prices. This level of error can be considered large, but it's important to compare this against the range and average of the actual prices in your dataset to better contextualize it.\n",
    "R^2 Score of 0.453: This score indicates that approximately 45.3% of the variance in the Price is explained by the model. While not extremely low, this score suggests there is significant room for improvement, as more than half of the variance is still unaccounted for by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "[CV] END regressor__max_depth=None, regressor__min_samples_leaf=1, regressor__n_estimators=100; total time=   2.6s\n",
      "[CV] END regressor__max_depth=None, regressor__min_samples_leaf=1, regressor__n_estimators=100; total time=   3.5s\n",
      "[CV] END regressor__max_depth=None, regressor__min_samples_leaf=1, regressor__n_estimators=100; total time=   2.6s\n",
      "[CV] END regressor__max_depth=None, regressor__min_samples_leaf=1, regressor__n_estimators=200; total time=   7.4s\n",
      "[CV] END regressor__max_depth=None, regressor__min_samples_leaf=1, regressor__n_estimators=200; total time=   8.8s\n",
      "[CV] END regressor__max_depth=None, regressor__min_samples_leaf=1, regressor__n_estimators=200; total time=   2.3s\n",
      "[CV] END regressor__max_depth=None, regressor__min_samples_leaf=2, regressor__n_estimators=100; total time=   0.9s\n",
      "[CV] END regressor__max_depth=None, regressor__min_samples_leaf=2, regressor__n_estimators=100; total time=   0.7s\n",
      "[CV] END regressor__max_depth=None, regressor__min_samples_leaf=2, regressor__n_estimators=100; total time=   0.6s\n",
      "[CV] END regressor__max_depth=None, regressor__min_samples_leaf=2, regressor__n_estimators=200; total time=   1.3s\n",
      "[CV] END regressor__max_depth=None, regressor__min_samples_leaf=2, regressor__n_estimators=200; total time=   1.2s\n",
      "[CV] END regressor__max_depth=None, regressor__min_samples_leaf=2, regressor__n_estimators=200; total time=   1.3s\n",
      "[CV] END regressor__max_depth=None, regressor__min_samples_leaf=4, regressor__n_estimators=100; total time=   0.5s\n",
      "[CV] END regressor__max_depth=None, regressor__min_samples_leaf=4, regressor__n_estimators=100; total time=   0.4s\n",
      "[CV] END regressor__max_depth=None, regressor__min_samples_leaf=4, regressor__n_estimators=100; total time=   0.5s\n",
      "[CV] END regressor__max_depth=None, regressor__min_samples_leaf=4, regressor__n_estimators=200; total time=   1.0s\n",
      "[CV] END regressor__max_depth=None, regressor__min_samples_leaf=4, regressor__n_estimators=200; total time=   1.0s\n",
      "[CV] END regressor__max_depth=None, regressor__min_samples_leaf=4, regressor__n_estimators=200; total time=   1.4s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=1, regressor__n_estimators=100; total time=   0.8s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=1, regressor__n_estimators=100; total time=   0.8s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=1, regressor__n_estimators=100; total time=   1.0s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=1, regressor__n_estimators=200; total time=   2.6s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=1, regressor__n_estimators=200; total time=   1.8s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=1, regressor__n_estimators=200; total time=   1.9s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=2, regressor__n_estimators=100; total time=   0.9s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=2, regressor__n_estimators=100; total time=   2.0s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=2, regressor__n_estimators=100; total time=   2.0s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=2, regressor__n_estimators=200; total time=   2.9s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=2, regressor__n_estimators=200; total time=   3.0s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=2, regressor__n_estimators=200; total time=   1.8s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=4, regressor__n_estimators=100; total time=   1.0s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=4, regressor__n_estimators=100; total time=   0.7s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=4, regressor__n_estimators=100; total time=   1.0s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=4, regressor__n_estimators=200; total time=   1.7s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=4, regressor__n_estimators=200; total time=   2.4s\n",
      "[CV] END regressor__max_depth=10, regressor__min_samples_leaf=4, regressor__n_estimators=200; total time=   3.2s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=1, regressor__n_estimators=100; total time=   1.5s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=1, regressor__n_estimators=100; total time=   2.7s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=1, regressor__n_estimators=100; total time=   3.0s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=1, regressor__n_estimators=200; total time=   3.1s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=1, regressor__n_estimators=200; total time=   3.9s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=1, regressor__n_estimators=200; total time=   2.8s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=2, regressor__n_estimators=100; total time=   0.9s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=2, regressor__n_estimators=100; total time=   1.1s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=2, regressor__n_estimators=100; total time=   0.9s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=2, regressor__n_estimators=200; total time=   2.7s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=2, regressor__n_estimators=200; total time=   2.5s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=2, regressor__n_estimators=200; total time=   2.1s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=4, regressor__n_estimators=100; total time=   1.4s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=4, regressor__n_estimators=100; total time=   1.0s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=4, regressor__n_estimators=100; total time=   0.7s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=4, regressor__n_estimators=200; total time=   1.5s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=4, regressor__n_estimators=200; total time=   1.5s\n",
      "[CV] END regressor__max_depth=20, regressor__min_samples_leaf=4, regressor__n_estimators=200; total time=   1.6s\n",
      "Best Model RMSE: 674346.660419937\n",
      "Best Model R^2 Score: 0.6918290538962881\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the pipeline with RandomForestRegressor\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Define a grid of parameters to search\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [100, 200],\n",
    "    'regressor__max_depth': [None, 10, 20],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(model_pipeline, param_grid, cv=3, scoring='neg_mean_squared_error', verbose=2)\n",
    "\n",
    "# Fit GridSearchCV to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Best Model RMSE: {rmse}')\n",
    "print(f'Best Model R^2 Score: {r2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of the Results\n",
    "Root Mean Squared Error (RMSE) of 674,346: This still indicates a sizable average error in predictions, but it's much reduced from the previous RMSE values. It's important to contextualize this value within the range and scale of house prices in your dataset. If house prices typically range in the millions, this RMSE might be more acceptable.\n",
    "R^2 Score of 0.691: This score has improved markedly from earlier models, suggesting that the model is capturing a significant portion of the variability in the house prices. An R^2 Score closer to 1.0 is ideal, but 0.691 is a robust score, particularly for real-world data which can be noisy and unpredictable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBRegressor\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Define the pipeline with XGBRegressor\u001b[39;00m\n\u001b[0;32m      4\u001b[0m xgb_pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m      5\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor),\n\u001b[0;32m      6\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgb_regressor\u001b[39m\u001b[38;5;124m'\u001b[39m, XGBRegressor(objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg:squarederror\u001b[39m\u001b[38;5;124m'\u001b[39m, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m))\n\u001b[0;32m      7\u001b[0m ])\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Define the pipeline with XGBRegressor\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('xgb_regressor', XGBRegressor(objective='reg:squarederror', n_estimators=200, learning_rate=0.05, max_depth=6, random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "xgb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_xgb = xgb_pipeline.predict(X_test)\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f'XGB Model RMSE: {rmse_xgb}')\n",
    "print(f'XGB Model R^2 Score: {r2_xgb}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
