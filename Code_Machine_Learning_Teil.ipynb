{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 402453.34764314984\n",
      "Feature Importances:\n",
      "Living Space (sqm): 0.3966270708717055\n",
      "Nearest Station Distance (m): 0.2072482481197514\n",
      "Canton_Geneva: 0.05450423177271926\n",
      "Canton_Zurich: 0.03841888647470974\n",
      "Canton_Jura: 0.027871856611456268\n",
      "Rooms: 0.025605411681375884\n",
      "Canton_Vaud: 0.025386318815425114\n",
      "view: 0.016911000625505067\n",
      "luxus: 0.015921392201184506\n",
      "terrace: 0.0154199835136841\n",
      "Canton_Graubuenden: 0.014999540251578616\n",
      "Canton_Zug: 0.014575490569795619\n",
      "garden: 0.013706512389831251\n",
      "Canton_Lucerne: 0.0094502350551034\n",
      "condition_new: 0.009190214487481072\n",
      "Canton_Schwyz: 0.008895067707785925\n",
      "Canton_Valais: 0.008888882531073745\n",
      "city_center: 0.008709061614484708\n",
      "Canton_Basel-Landschaft: 0.008303244169679945\n",
      "condition_old: 0.008113819385105043\n",
      "Canton_Basel-Stadt: 0.007779295833760928\n",
      "Canton_Neuchatel: 0.007066309940448477\n",
      "Canton_Ticino: 0.0066858251204269074\n",
      "Canton_Solothurn: 0.006435564837955883\n",
      "condition_renovated: 0.00615297168917211\n",
      "Canton_Aargau: 0.005954963895703494\n",
      "Canton_Bern: 0.0051522369139357805\n",
      "Canton_Fribourg: 0.004742810629652544\n",
      "Canton_Thurgau: 0.004087880634386197\n",
      "Canton_St-Gallen: 0.003972356983248383\n",
      "Canton_Obwalden: 0.0031977053241161817\n",
      "Canton_Appenzell-Ausser-Rhoden: 0.002188421124809432\n",
      "Canton_Schaffhausen: 0.0020304504684532433\n",
      "Canton_Uri: 0.0018952888615247124\n",
      "Canton_Glarus: 0.0018277274328288426\n",
      "Canton_Nidwalden: 0.001651576027670667\n",
      "Canton_Appenzell-Inner-Rhoden: 0.00043214543247014535\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error, root_mean_squared_error\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('final_filtered_NLP_immoscout24.csv')\n",
    "\n",
    "# Drop columns that won't be used\n",
    "data = data.drop(['Address', 'Title', 'Description', 'Price_per_SquareMeter'], axis=1)\n",
    "\n",
    "# Correctly handle missing values without inplace=True\n",
    "data['Rooms'] = data['Rooms'].fillna(data['Rooms'].median())\n",
    "data['Living Space (sqm)'] = data['Living Space (sqm)'].fillna(data['Living Space (sqm)'].median())\n",
    "data['Nearest Station Distance (m)'] = data['Nearest Station Distance (m)'].fillna(data['Nearest Station Distance (m)'].median())\n",
    "\n",
    "# Convert categorical 'Canton' and 'Condition' to numeric using OneHotEncoder\n",
    "categorical_features = ['Canton', 'condition']\n",
    "numeric_features = ['Rooms', 'Living Space (sqm)', 'Nearest Station Distance (m)', 'city_center', 'garden', 'terrace', 'view', 'luxus']\n",
    "\n",
    "# Create a Column Transformer to handle the preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define the model\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop('Price', axis=1)\n",
    "y = data['Price']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using root mean squared error directly\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "\n",
    "# Get feature importances from the model\n",
    "feature_importances = model.named_steps['regressor'].feature_importances_\n",
    "# Correct method to get the names after transformation\n",
    "encoded_features = model.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
    "features = numeric_features + list(encoded_features)\n",
    "\n",
    "# Print feature importance\n",
    "feature_importance_dict = dict(zip(features, feature_importances))\n",
    "sorted_features = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"Feature Importances:\")\n",
    "for name, importance in sorted_features:\n",
    "    print(f\"{name}: {importance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 405203.8203927445\n",
      "Canton_Geneva: 0.13125596940517426\n",
      "Canton_Jura: 0.12096162140369415\n",
      "Canton_Zurich: 0.09513138234615326\n",
      "Canton_Vaud: 0.0690147802233696\n",
      "Living Space (sqm): 0.058032602071762085\n",
      "Canton_Solothurn: 0.05625741928815842\n",
      "Canton_Zug: 0.05055336654186249\n",
      "Canton_Valais: 0.048523418605327606\n",
      "Canton_Neuchatel: 0.03652404993772507\n",
      "Canton_Lucerne: 0.03407268226146698\n",
      "Canton_Graubuenden: 0.03136114403605461\n",
      "Canton_Basel-Stadt: 0.03088955581188202\n",
      "Canton_Schwyz: 0.030306942760944366\n",
      "Canton_Bern: 0.02420995756983757\n",
      "Canton_Fribourg: 0.024197252467274666\n",
      "Canton_Basel-Landschaft: 0.018652116879820824\n",
      "Canton_Glarus: 0.017911778762936592\n",
      "Canton_Obwalden: 0.01433262974023819\n",
      "Canton_St-Gallen: 0.014281773939728737\n",
      "condition_renovated: 0.012157050892710686\n",
      "Canton_Aargau: 0.011234627105295658\n",
      "Canton_Ticino: 0.010701412335038185\n",
      "Nearest Station Distance (m): 0.008554065600037575\n",
      "Canton_Nidwalden: 0.008292359299957752\n",
      "Canton_Schaffhausen: 0.007698873057961464\n",
      "Canton_Appenzell-Ausser-Rhoden: 0.006420827470719814\n",
      "condition_new: 0.006267457734793425\n",
      "Canton_Uri: 0.005586552433669567\n",
      "Canton_Thurgau: 0.005375663284212351\n",
      "Rooms: 0.004388707689940929\n",
      "condition_old: 0.0034599683713167906\n",
      "Canton_Appenzell-Inner-Rhoden: 0.003391987644135952\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('final_filtered_NLP_immoscout24.csv')\n",
    "\n",
    "# Drop unwanted columns\n",
    "data = data.drop(['Address', 'Title', 'Description', 'Price_per_SquareMeter'], axis=1)\n",
    "\n",
    "# Select only numeric columns for median calculation\n",
    "numeric_cols = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].median())\n",
    "\n",
    "# Define categorical and numeric features\n",
    "categorical_features = ['Canton', 'condition']\n",
    "numeric_features = data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "numeric_features.remove('Price')  # Exclude the target variable\n",
    "\n",
    "# Preprocessing for numeric and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define the XGBoost regressor within a pipeline\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=300, learning_rate=0.05, max_depth=5)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', xgb_model)\n",
    "])\n",
    "\n",
    "# Train-test split\n",
    "X = data.drop('Price', axis=1)\n",
    "y = data['Price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model using RMSE\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "\n",
    "# Feature importance (requires handling of feature names post OneHotEncoding)\n",
    "encoder_features = pipeline.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
    "features = numeric_features + list(encoder_features)\n",
    "importances = pipeline.named_steps['regressor'].feature_importances_\n",
    "\n",
    "# Print sorted feature importance\n",
    "feature_importance_dict = dict(zip(features, importances))\n",
    "sorted_features = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "for name, importance in sorted_features:\n",
    "    print(f\"{name}: {importance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 292588.72\n",
      "Mean Squared Error (MSE): 164190136060.88\n",
      "Root Mean Squared Error (RMSE): 405203.82\n",
      "R-squared: 0.60\n",
      "Adjusted R-squared: 0.60\n",
      "Mean Squared Logarithmic Error (MSLE): 0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andrea\\anaconda3\\envs\\adsenv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_squared_log_error\n",
    "\n",
    "# Assuming y_test are the actual values and y_pred are the model's predictions\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)  # or use root_mean_squared_error\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = len(y_test)  # number of data points\n",
    "p = X_test.shape[1]  # number of predictors\n",
    "adj_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "print(f\"Adjusted R-squared: {adj_r2:.2f}\")\n",
    "\n",
    "# Calculate Mean Squared Logarithmic Error (MSLE)\n",
    "# Ensure no zero or negative values in predictions or actuals\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Logarithmic Error (MSLE): {msle:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
