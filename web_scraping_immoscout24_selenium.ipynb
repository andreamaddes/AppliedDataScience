{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping page 6...\n",
      "Scraping page 7...\n",
      "Scraping page 8...\n",
      "Scraping page 9...\n",
      "Scraping page 10...\n",
      "Scraping page 11...\n",
      "Scraping page 12...\n",
      "Scraping page 13...\n",
      "Scraping page 14...\n",
      "Scraping page 15...\n",
      "Scraping page 16...\n",
      "Scraping page 17...\n",
      "Scraping page 18...\n",
      "Scraping page 19...\n",
      "Scraping page 20...\n",
      "Scraping page 21...\n",
      "Scraping page 22...\n",
      "Scraping page 23...\n",
      "Scraping page 24...\n",
      "Scraping page 25...\n",
      "Scraping page 26...\n",
      "Scraping page 27...\n",
      "Scraping page 28...\n",
      "Scraping page 29...\n",
      "Scraping page 30...\n",
      "Scraping page 31...\n",
      "Scraping page 32...\n",
      "Scraping page 33...\n",
      "Scraping page 34...\n",
      "Scraping page 35...\n",
      "Scraping page 36...\n",
      "Scraping page 37...\n",
      "Scraping page 38...\n",
      "Scraping page 39...\n",
      "Scraping page 40...\n",
      "Scraping page 41...\n",
      "Scraping page 42...\n",
      "Scraping page 43...\n",
      "Scraping page 44...\n",
      "Scraping page 45...\n",
      "Scraping page 46...\n",
      "Scraping page 47...\n",
      "Scraping page 48...\n",
      "Scraping page 49...\n",
      "                                    Address  \\\n",
      "0                               1963 Vétroz   \n",
      "1                       Dorf 7, 3305 Iffwil   \n",
      "2    Chemin de la Farette 4, 1232 Confignon   \n",
      "3           Lutisbachweg 10, 6315 Oberägeri   \n",
      "4       Allmendgütlistrasse 43, 8810 Horgen   \n",
      "..                                      ...   \n",
      "975                            5082 Kaisten   \n",
      "976            Lagerhausweg 5, 8424 Embrach   \n",
      "977       Chemin d'Aiguerosse 3, 1882 Gryon   \n",
      "978                           6825 Capolago   \n",
      "979               via besso 59, 6814 Lamone   \n",
      "\n",
      "                                                 Title  \\\n",
      "0    Vétroz - Appartement de 1.5 pièces avec grand ...   \n",
      "1    Moderne 4 1/2 Maisonette-Wohnung im historisch...   \n",
      "2             Appartement neuf avec jardin et terrasse   \n",
      "3                EDENBLICK - In 15 Minuten im Paradies   \n",
      "4               AURA - Letzte idyllische Gartenwohnung   \n",
      "..                                                 ...   \n",
      "975               TRAUMHAUS AVA ZUM ATTRAKTIVEN PREIS!   \n",
      "976                                           RUSTIKAL   \n",
      "977                            1882 Gryon, Réf 4835595   \n",
      "978  NUOVO ECCEZIONALE PREZZO Esclusivo attico di d...   \n",
      "979   Vendesi ampio e lussuoso 1.5 locali con giardino   \n",
      "\n",
      "                                           Description      Rooms  \\\n",
      "0    EXCLUSIVITÉ SCHMIDTCet appartement de 1.5 pièc...  1.5 rooms   \n",
      "1    Das Areal Kreuz Iffwil wurde von 2022-2024 ren...  1.5 rooms   \n",
      "2    DESCRIPTION:Sur le coteau sud de Confignon ave...     1 room   \n",
      "3    Hier sind Sie auf der Sonnenseite zuhauseIn Ob...  1.5 rooms   \n",
      "4    Termin online buchen - bitte Link kopieren: ht...  1.5 rooms   \n",
      "..                                                 ...        ...   \n",
      "975                                                     1.5 rooms   \n",
      "976                                                     1.5 rooms   \n",
      "977  Caractéristiques du Chalet :Emplacement idylli...  2.5 rooms   \n",
      "978  In posizione esclusiva e privilegiata con otti...  2.5 rooms   \n",
      "979                                                     1.5 rooms   \n",
      "\n",
      "    Living Space (sqm) Price  \n",
      "0                130m²     ,  \n",
      "1                120m²     ,  \n",
      "2                150m²     ,  \n",
      "3                140m²     ,  \n",
      "4                120m²     ,  \n",
      "..                 ...   ...  \n",
      "975              130m²     ,  \n",
      "976              160m²     ,  \n",
      "977              380m²     ,  \n",
      "978              330m²     ,  \n",
      "979               25m²     ,  \n",
      "\n",
      "[980 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def scrape_apartments(url):\n",
    "    # Setup ChromeDriver\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')  # Run Chrome in headless mode (no GUI)\n",
    "    \n",
    "    # Initialize lists to store data\n",
    "    addresses = []\n",
    "    titles = []\n",
    "    descriptions = []\n",
    "    rooms = []\n",
    "    living_space = []\n",
    "    prices = []\n",
    "\n",
    "    # Loop through the 50 pages\n",
    "    for page_num in range(1, 50):\n",
    "        print(f\"Scraping page {page_num}...\")\n",
    "        driver = webdriver.Chrome(service=service, options=options)  # Define driver within the loop\n",
    "        page_url = f\"{url}?page={page_num}\"\n",
    "        driver.get(page_url)\n",
    "        time.sleep(3)  # Add a delay to allow the page to load\n",
    "\n",
    "        # Get the full content of the website\n",
    "        source = driver.page_source\n",
    "\n",
    "        # Parse HTML content with BeautifulSoup\n",
    "        soup = BeautifulSoup(source, 'html.parser')\n",
    "\n",
    "        # Get addresses\n",
    "        address_elements = soup.find_all(class_='HgListingCard_address_JGiFv')\n",
    "        for element in address_elements:\n",
    "            address = element.find('address').text.strip()\n",
    "            addresses.append(address)\n",
    "\n",
    "        # Get titles and descriptions\n",
    "        title_desc_elements = soup.find_all(class_='HgListingDescription_description_r5HCO')\n",
    "        for element in title_desc_elements:\n",
    "            title = element.find('span').text.strip()\n",
    "            description_elem = element.find('p', class_='HgListingDescription_large_uKs3J')\n",
    "            description = description_elem.text.strip() if description_elem else ''\n",
    "            titles.append(title)\n",
    "            descriptions.append(description)\n",
    "\n",
    "        # Get rooms, living space, and prices\n",
    "        room_space_price_elements = soup.find_all(class_='HgListingRoomsLivingSpacePrice_roomsLivingSpacePrice_M6Ktp')\n",
    "        for element in room_space_price_elements:\n",
    "            strong_tags = element.find_all('strong')\n",
    "            rooms.append(strong_tags[0].text.strip()) if strong_tags else rooms.append('')\n",
    "            living_space.append(strong_tags[1].text.strip()) if len(strong_tags) > 1 else living_space.append('')\n",
    "            prices.append(element.find('span').text.strip())\n",
    "\n",
    "        # Close driver\n",
    "        driver.quit()\n",
    "\n",
    "    # Ensure all arrays have the same length\n",
    "    data_length = min(len(addresses), len(titles), len(descriptions), len(rooms), len(living_space), len(prices))\n",
    "\n",
    "    # Dataframe\n",
    "    df = pd.DataFrame({'Address': addresses[:data_length],\n",
    "                       'Title': titles[:data_length],\n",
    "                       'Description': descriptions[:data_length],\n",
    "                       'Rooms': rooms[:data_length],\n",
    "                       'Living Space (sqm)': living_space[:data_length],\n",
    "                       'Price': prices[:data_length]})\n",
    "\n",
    "    # Save to file\n",
    "    df.to_csv('immoscout24.csv', sep=\";\", index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Specify the URL to scrape\n",
    "url = 'https://www.immoscout24.ch/en/real-estate/buy/country-switzerland-fl'\n",
    "\n",
    "# Run the scraping function and display the results\n",
    "apartment_data = scrape_apartments(url)\n",
    "print(apartment_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
